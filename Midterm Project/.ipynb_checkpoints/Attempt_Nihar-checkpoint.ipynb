{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e03dc791-583b-43a0-ad37-3eb9940afd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install prince"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c29452a-a175-4f53-99ec-c187b334714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eda5164-3705-427b-8905-1d91caaeede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731d295b",
   "metadata": {},
   "source": [
    "## Midterm Project\n",
    "\n",
    "### Amogh Ranganathaiah (aranganathaiah@sfsu.edu)\n",
    "### Ekta Singh (esingh@sfsu.edu)\n",
    "### Nihar Shah (nshah4@sfsu.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a74612",
   "metadata": {},
   "source": [
    "### PART 1: Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98be9032-5e32-427c-8854-977b390ed047",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import prince\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gower\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.metrics import normalized_mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccf8cf4-e15b-4cc3-8342-96370ebaaa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set\n",
    "data = pd.read_csv('train.csv')\n",
    "data = data.drop('Id', axis=1)\n",
    "\n",
    "# Remove columns with too many missing values\n",
    "data = data.drop(data.columns[data.isnull().sum() > 30], axis=1)\n",
    "\n",
    "# Remove remaining missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Separate categorical and numerical features\n",
    "# Categorical features are text-based and identified using 'object' dtype\n",
    "categorical_features = data.select_dtypes(include=['object'])\n",
    "numerical_features = data.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Split categorical and numerical features into training and test sets\n",
    "# 20% of the data is reserved for testing, with the remaining 80% used for training\n",
    "# random_state ensures reproducibility of results\n",
    "X_train_cat, X_test_cat, X_train_num, X_test_num = train_test_split(\n",
    "    categorical_features, numerical_features, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130900e",
   "metadata": {},
   "source": [
    "1. Dropping columns: Columns with excessive missing values are removed since they may negatively impact the model’s performance.\n",
    "2. Handling missing data: Any rows with remaining missing values are removed to ensure the data is complete.\n",
    "3. Categorical and numerical separation: Categorical features (text-based) and numerical features (numbers) are separated, as they may need different preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d089d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure train and test categorical data have the same levels\n",
    "keep = X_train_cat.nunique() == X_test_cat.nunique()\n",
    "X_train_cat = X_train_cat[X_train_cat.columns[keep]]\n",
    "X_test_cat = X_test_cat[X_test_cat.columns[keep]]\n",
    "\n",
    "# Ensure the classes in training and testing are the same\n",
    "keep = []\n",
    "for i in range(X_train_cat.shape[1]):\n",
    "    keep.append(all(np.sort(X_train_cat.iloc[:, i].unique()) == np.sort(X_test_cat.iloc[:, i].unique())))\n",
    "X_train_cat = X_train_cat[X_train_cat.columns[keep]]\n",
    "X_test_cat = X_test_cat[X_test_cat.columns[keep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102f5db9-217b-47d6-96d0-05bb89f58606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimension Reduction\n",
    "\n",
    "# Scaling the numerical features\n",
    "# StandardScaler standardizes the data by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num)\n",
    "X_test_num_scaled = scaler.transform(X_test_num)\n",
    "\n",
    "# Apply PCA (Principal Component Analysis) on scaled numerical features\n",
    "pca = PCA(n_components=35) \n",
    "X_train_pca = pca.fit_transform(X_train_num_scaled)\n",
    "X_test_pca = pca.transform(X_test_num_scaled)\n",
    "\n",
    "# Apply MCA (Multiple Correspondence Analysis) on categorical features\n",
    "mca = prince.MCA(n_components=1) \n",
    "X_train_mca = mca.fit_transform(X_train_cat)\n",
    "X_test_mca = mca.transform(X_test_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81469942",
   "metadata": {},
   "source": [
    "1. PCA reduces the dimensionality of the numerical data, keeping only the most important components\n",
    "2. n_components=35: This retains 35 principal components based on prior hyperparameter tuning\n",
    "3. Error was encountered beyond 36 components, due to the number of features being less than 36\n",
    "4. MCA is similar to PCA but is used for categorical data to reduce dimensionality\n",
    "5. n_components=1: Reduces the categorical data to a single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d533c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE (on reduced features): 3630.04\n",
      "Ridge Regression RMSE (on reduced features): 60.25\n"
     ]
    }
   ],
   "source": [
    "# Combine PCA and MCA results for training and test sets\n",
    "X_train_combined = np.hstack((X_train_pca, X_train_mca))\n",
    "X_test_combined = np.hstack((X_test_pca, X_test_mca))\n",
    "\n",
    "# Perform Ridge regression on the reduced features\n",
    "y_train = data.loc[X_train_cat.index, 'SalePrice']\n",
    "y_test = data.loc[X_test_cat.index, 'SalePrice']\n",
    "\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X_train_combined, y_train)\n",
    "y_pred_test = ridge.predict(X_test_combined)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_test)\n",
    "print(f'Ridge Regression MSE (on reduced features): {mse:.2f}')\n",
    "print(f'Ridge Regression RMSE (on reduced features): {mse**0.5:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d5ed07",
   "metadata": {},
   "source": [
    "### Interpretation of the Results:\n",
    "1. MSE (3630.04) shows the overall squared error magnitude, but it's harder to interpret directly.\n",
    "2. RMSE (60.25) provides a clearer idea of how far off your model's predictions are from the actual values. A lower RMSE is preferred, as it indicates better predictive performance.\n",
    "\n",
    "During the process of model tuning, we opted not to change the alpha value significantly because increasing or decreasing it too much could result in overfitting or underfitting the model. In Ridge Regression, the alpha parameter controls the amount of regularization applied to the model—higher values of alpha increase regularization, while lower values reduce it.\n",
    "\n",
    "Through experimentation, we found a suitable alpha value that balances the model's bias and variance. Increasing the alpha beyond this point would overly constrain the model and risk underfitting, while decreasing it too much would remove the regularization effect, leading to overfitting, especially after dimensionality reduction. Therefore, we settled on the current alpha value as it produced the best balance between model complexity and prediction accuracy, as reflected in the MSE and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9781cd3c-c43d-46db-8753-87a95329f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE: Regression on Original Data\n",
    "\n",
    "# Create dummy variables for categorical features\n",
    "X_train_cat_dummies = pd.get_dummies(X_train_cat, drop_first=True)\n",
    "X_test_cat_dummies = pd.get_dummies(X_test_cat, drop_first=True)\n",
    "\n",
    "# Combine numerical and categorical data\n",
    "X_train_original = pd.concat([pd.DataFrame(X_train_num_scaled, index=X_train_num.index), X_train_cat_dummies], axis=1)\n",
    "X_test_original = pd.concat([pd.DataFrame(X_test_num_scaled, index=X_test_num.index), X_test_cat_dummies], axis=1)\n",
    "\n",
    "# Ensure all column names are strings\n",
    "X_train_original.columns = X_train_original.columns.astype(str)\n",
    "X_test_original.columns = X_test_original.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6631448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression MSE (on original features): 6646.60\n",
      "Ridge Regression RMSE (on reduced features): 81.53\n"
     ]
    }
   ],
   "source": [
    "# Fit Ridge regression on the original data\n",
    "ridge.fit(X_train_original, y_train)\n",
    "y_pred_test_original = ridge.predict(X_test_original)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "mse_original = mean_squared_error(y_test, y_pred_test_original)\n",
    "print(f'Ridge Regression MSE (on original features): {mse_original:.2f}')\n",
    "print(f'Ridge Regression RMSE (on reduced features): {mse_original**0.5:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343e5428",
   "metadata": {},
   "source": [
    "### Interpretation of the Results:\n",
    "1. The higher MSE (6646.60) and RMSE (81.53) on the original features indicate that the model performs worse on the full dataset compared to the reduced feature set.\n",
    "2. The RMSE of 81.53 shows that the model has a larger average prediction error when using all features, which may indicate that the original feature set includes irrelevant or redundant features that add noise rather than improving predictive power.\n",
    "\n",
    "The results on the reduced feature set (MSE: 6646.60, RMSE: 81.53) are better, showing that dimensionality reduction (via PCA and MCA) helped improve the model's predictive accuracy. By removing less important or redundant features, the model becomes more efficient and generalizes better, as indicated by the lower error metrics.\n",
    "\n",
    "Just as with the reduced feature set, we chose not to significantly adjust the alpha parameter in the Ridge Regression model to avoid overfitting. Increasing the alpha too much on the original data could have overly constrained the model, while decreasing it would have led to overfitting, especially given the presence of many original features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238e768",
   "metadata": {},
   "source": [
    "### PART 2: Clustering Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "865794bb-a7c5-4476-a96a-33c6005f3228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Mutual Information Score: 0.25\n"
     ]
    }
   ],
   "source": [
    "# Compute Gower distance matrix for the full data (no train/test split)\n",
    "full_data = pd.concat([numerical_features, categorical_features], axis=1)\n",
    "gower_dist = gower.gower_matrix(full_data)\n",
    "\n",
    "# Apply K-medoids clustering with Gower distance\n",
    "kmedoids = KMedoids(n_clusters=6, metric='precomputed', random_state=42)\n",
    "cluster_labels = kmedoids.fit_predict(gower_dist)\n",
    "\n",
    "# Bin the response variable (SalePrice) into 3 groups using qcut\n",
    "binned_price = pd.qcut(data['SalePrice'], q=3, labels=False)\n",
    "\n",
    "# Compute Normalized Mutual Information (NMI) between clustering results and binned response\n",
    "nmi_score = normalized_mutual_info_score(binned_price, cluster_labels)\n",
    "print(f'Normalized Mutual Information Score: {nmi_score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8938f93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "271de9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of clusters: 2 with NMI Score: 0.40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, normalized_mutual_info_score\n",
    "\n",
    "# Compute Gower distance matrix for the full data (no train/test split)\n",
    "full_data = pd.concat([numerical_features, categorical_features], axis=1)\n",
    "\n",
    "# This line computes the Gower distance matrix, which is a measure that handles mixed numerical and categorical data. \n",
    "# The resulting matrix is square and contains the pairwise distances between every pair of rows (instances) in your dataset. \n",
    "# Each entry in the matrix represents the Gower distance between two data points.\n",
    "gower_dist = gower.gower_matrix(full_data)\n",
    "\n",
    "# Bin the response variable (SalePrice) into 3 groups using qcut\n",
    "binned_price = pd.qcut(data['SalePrice'], q=2, labels=False)\n",
    "\n",
    "# Ensure binned_price has the same index as full_data (important for alignment)\n",
    "binned_price = binned_price.loc[full_data.index]\n",
    "\n",
    "# Define a custom cross-validator\n",
    "# The K-medoids algorithm requires a square distance matrix when fitting (training) the model. \n",
    "# However, during prediction, we want to use the distances between the test samples and the medoids selected during training. \n",
    "# Therefore, the matrix provided for test samples is rectangular, reflecting the test-to-train distances.\n",
    "def custom_cv(X, y, cv=3):\n",
    "    skf = StratifiedKFold(n_splits=cv)\n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        # Since we are using precomputed distance, ensure we select the correct rows and columns\n",
    "        train_dist = X[np.ix_(train_idx, train_idx)]\n",
    "        test_dist = X[np.ix_(test_idx, train_idx)]  # Distance between test samples and training medoids\n",
    "        yield (train_dist, test_dist, y.iloc[train_idx], y.iloc[test_idx])\n",
    "\n",
    "\n",
    "# Training vs. Test Separation: During cross-validation, you cannot use test samples to determine cluster centroids (medoids). \n",
    "# Hence, we only use distances between test samples and the medoids selected from the \n",
    "# training data to predict the clusters for the test set.\n",
    "\n",
    "# When using precomputed distances, we must handle the distance matrix carefully to ensure that the \n",
    "# model fits on training data and predicts using the appropriate medoids for the test data.\n",
    "\n",
    "# Define a custom scorer for Normalized Mutual Information (NMI)\n",
    "def nmi_scorer(estimator, X_train, y_train, X_test, y_test):\n",
    "    # Fit the K-medoids model on the training set\n",
    "    estimator.fit(X_train)\n",
    "    \n",
    "    # Predict the cluster labels for the test set based on the training medoids\n",
    "    labels_test = estimator.predict(X_test)\n",
    "    \n",
    "    # Return NMI between the predicted labels and the true labels of the test set\n",
    "    return normalized_mutual_info_score(y_test, labels_test)\n",
    "\n",
    "# Create a custom scorer based on NMI\n",
    "nmi_score_custom = make_scorer(nmi_scorer, greater_is_better=True, needs_proba=False)\n",
    "\n",
    "# Tuning parameter grid\n",
    "param_dist = {'n_clusters': np.arange(2, 10)}\n",
    "\n",
    "# Custom implementation of the cross-validation loop\n",
    "best_score = -np.inf\n",
    "best_param = None\n",
    "\n",
    "# Iterate through the number of clusters\n",
    "for n_clusters in param_dist['n_clusters']:\n",
    "    scores = []\n",
    "    \n",
    "    # Perform custom cross-validation\n",
    "    for train_dist, test_dist, y_train, y_test in custom_cv(gower_dist, binned_price, cv=3):\n",
    "        # Apply KMedoids with precomputed distance\n",
    "        kmedoids = KMedoids(n_clusters=n_clusters, metric='precomputed', random_state=42)\n",
    "        \n",
    "        # Evaluate NMI on the test set\n",
    "        score = nmi_scorer(kmedoids, train_dist, y_train, test_dist, y_test)\n",
    "        scores.append(score)\n",
    "\n",
    "    # Get the average score across all folds\n",
    "    mean_score = np.mean(scores)\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_param = n_clusters\n",
    "\n",
    "# Print the best number of clusters and corresponding NMI score\n",
    "print(f'Best number of clusters: {best_param} with NMI Score: {best_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959d88f2",
   "metadata": {},
   "source": [
    "**Why Do We Need This Approach?**\n",
    "1. Precomputed Distance Matrix: The Gower distance matrix contains pairwise distances between all data points, but we can't simply split this matrix like we would with raw data (e.g., numerical or categorical features). The challenge with cross-validation in this context is to ensure that the training and test distance matrices are correctly aligned to avoid shape mismatch errors.\n",
    "\n",
    "2. Clustering Evaluation: NMI is used to evaluate the agreement between the predicted clusters and the actual labels (binned_price). By carefully using the train-test splits, we ensure that the model is evaluated on unseen data, giving us a fair assessment of clustering performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f488533d",
   "metadata": {},
   "source": [
    "The reason why the NMI Score is only 0.40 could be because:\n",
    "1. Clustering algorithms, especially when using a mixed distance metric like Gower distance, might struggle with datasets that have many categorical features and missing values. If the data is sparse or the categorical variables dominate the distance calculations, the clusters formed might not align well with the ground truth labels.\n",
    "2. K-medoids clustering tends to form clusters based on the central representative points (medoids), but when you have a significant amount of categorical data, it can be challenging to find clear-cut clusters. This can result in low mutual information when compared to the SalePrice labels, as SalePrice might be more influenced by specific numerical features (like OverallQual, GrLivArea, etc.) than categorical ones.\n",
    "3. The algorithm found that 2 clusters were optimal based on your configuration. This could suggest that the dataset is not highly differentiable into multiple clusters or that the main differentiating features are too subtle for K-medoids to detect beyond 2 broad groupings.\n",
    "4. With 81 features, many of which might be irrelevant or redundant, the distance calculation may suffer from the \"curse of dimensionality.\" This dilutes the strength of the clusters, as noise from irrelevant features may obscure important patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648c2b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
